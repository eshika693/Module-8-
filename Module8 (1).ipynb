{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Ques1) What is NumPy, and why is it widely used in Python?"
      ],
      "metadata": {
        "id": "K9qM3zGCaZUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NumPy (Numerical Python) is a powerful open-source library in Python used primarily for numerical and scientific computing. It provides a high-performance multidimensional array object called ndarray, which allows for efficient storage and manipulation of large datasets. NumPy is widely used because it enables fast mathematical operations on arrays and matrices, supports broadcasting (which simplifies code when working with arrays of different shapes), and offers a wide range of built-in functions for linear algebra, statistics, and other numerical tasks. Additionally, NumPy is the foundation for many other popular libraries like Pandas, SciPy, and scikit-learn, making it an essential tool in the data science and machine learning ecosystem. Its performance, ease of use, and versatility have made it a go-to library for both beginners and professionals working with numerical data in Python.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_qPwVGxDafuU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques2) How does broadcasting work in NumPy?"
      ],
      "metadata": {
        "id": "Az9TwB9ear3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Broadcasting in NumPy is a powerful feature that allows arrays of different shapes to be used in arithmetic operations without the need for explicit replication of data. When performing operations on two arrays, NumPy compares their shapes element-wise, starting from the trailing dimensions. If the dimensions are equal or one of them is 1, the operation is allowed, and NumPy automatically \"broadcasts\" the smaller array across the larger one to match its shape. This makes code more efficient and concise by eliminating the need for manually reshaping or duplicating data. For example, adding a 1D array to each row of a 2D array is seamlessly handled by broadcasting. While it simplifies many operations, understanding the rules of broadcasting is important to avoid unexpected results and ensure that operations behave as intended."
      ],
      "metadata": {
        "id": "VZctWMsqa2bt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques3) What is a Pandas DataFrame?"
      ],
      "metadata": {
        "id": "qgWmYbuOa9P9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A Pandas DataFrame is a two-dimensional, size-mutable, and heterogeneous data structure in Python, widely used for data manipulation and analysis. It can be thought of as a table or spreadsheet with labeled rows and columns, where each column can hold data of different types such as integers, floats, strings, or even objects. Built on top of NumPy, the DataFrame offers powerful tools for selecting, filtering, grouping, merging, and reshaping data. Its intuitive structure and rich functionality make it a go-to choice for data scientists and analysts when working with structured data, such as data from CSV files, Excel spreadsheets, or SQL databases. With Pandas, complex data operations can be performed with minimal and readable code, making it a cornerstone of the Python data analysis ecosystem.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sCGHHYdrbFLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques4) Explain the use of the groupby() method in Pandas?"
      ],
      "metadata": {
        "id": "zFXuP4tXbLIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The groupby() method in Pandas is a powerful tool used for grouping and aggregating data based on one or more columns. It allows you to split a DataFrame into groups, apply a function to each group independently, and then combine the results. This is especially useful for analyzing and summarizing data by categories or classifications, such as calculating the average sales per region or total revenue per product category. When you use groupby(), Pandas creates a GroupBy object that you can then apply aggregation functions to, like sum(), mean(), count(), or even custom functions. This method supports clean and efficient data analysis workflows, enabling you to derive meaningful insights from large and complex datasets with just a few lines of code."
      ],
      "metadata": {
        "id": "x_1dJIz1bPMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques5)  Why is Seaborn preferred for statistical visualizations?"
      ],
      "metadata": {
        "id": "0kQOq1NpbXNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Seaborn is preferred for statistical visualizations in Python because it provides a high-level interface for creating attractive and informative graphics with minimal code. Built on top of Matplotlib and closely integrated with Pandas, Seaborn simplifies the process of visualizing complex datasets by offering built-in support for common statistical plots such as box plots, violin plots, bar plots, and heatmaps. It also handles data frames directly, allowing for easy mapping of variables to visual elements like color and size. Additionally, Seaborn includes powerful features for visualizing relationships between multiple variables and automatically performing statistical aggregation, making it ideal for exploratory data analysis. Its aesthetically pleasing default styles and ability to quickly reveal trends and patterns in data have made it a popular choice among data scientists and analysts."
      ],
      "metadata": {
        "id": "TsPdO4zMbc3H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques6) What are the differences between NumPy arrays and Python lists?"
      ],
      "metadata": {
        "id": "j0ZdY0jVbiUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NumPy arrays and Python lists are both used to store collections of data, but they differ significantly in structure, performance, and functionality. A key difference is that NumPy arrays are homogeneous, meaning all elements must be of the same data type, while Python lists are heterogeneous and can hold elements of different types. NumPy arrays are more memory-efficient and allow for faster computation because they are implemented in C and support vectorized operations, enabling element-wise calculations without explicit loops. In contrast, Python lists are more flexible but slower when it comes to numerical computations, especially on large datasets. Additionally, NumPy provides a wide range of mathematical functions and supports multi-dimensional arrays, making it ideal for scientific and numerical computing, whereas Python lists are best suited for general-purpose programming and simpler data storage tasks.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AIriDU0Cbmx7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques7) What is a heatmap, and when should it be used?"
      ],
      "metadata": {
        "id": "m_aGJBWMbtQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A heatmap is a data visualization technique that uses color to represent the values of a matrix or two-dimensional data. In a heatmap, different shades or intensities of color indicate variations in the data, making it easy to identify patterns, trends, correlations, or outliers at a glance. Heatmaps are especially useful when dealing with large datasets where numeric values might be overwhelming to interpret in raw form. They are commonly used in fields like statistics, data analysis, and machine learning to visualize things like correlation matrices, feature importance, or frequency distributions. For example, in exploratory data analysis, a heatmap can quickly show how different variables in a dataset are correlated, helping analysts decide which features may be important for modeling."
      ],
      "metadata": {
        "id": "I6mhFp3FbyOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques8) What does the term “vectorized operation” mean in NumPy?"
      ],
      "metadata": {
        "id": "BESc2-BIb3Pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In NumPy, the term “vectorized operation” refers to the process of performing operations on entire arrays or large blocks of data at once, rather than iterating through elements with explicit loops. This approach takes advantage of low-level optimizations and underlying C code, making computations significantly faster and more efficient than standard Python loops. Vectorized operations allow you to write clean, concise, and readable code while benefiting from better performance. For example, adding two arrays element-wise or applying a mathematical function like np.sqrt() to every element in an array can be done in a single line using vectorization. This concept is central to NumPy’s design and is one of the key reasons it is widely used for numerical and scientific computing in Python."
      ],
      "metadata": {
        "id": "9J6fgt3Sb7W7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques9) How does Matplotlib differ from Plotly?"
      ],
      "metadata": {
        "id": "DVDz7ninb_zM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Matplotlib and Plotly are both popular Python libraries for data visualization, but they differ significantly in terms of functionality, interactivity, and use cases. Matplotlib is a foundational plotting library that offers extensive control over static, publication-quality visualizations. It is highly customizable and widely used in the scientific and academic communities for creating basic plots like line charts, bar graphs, and histograms. However, it produces static images by default, which lack interactivity. On the other hand, Plotly is designed for creating interactive and web-based visualizations. It allows users to zoom, hover, and click on elements within a chart, making it ideal for dashboards and data exploration. Plotly is especially useful in web applications and business analytics environments where user interaction enhances data interpretation. While Matplotlib is powerful for static and detailed customization, Plotly stands out for its modern, interactive visual appeal and ease of use in sharing visualizations online."
      ],
      "metadata": {
        "id": "xq61EIqQcDYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques10)  What is the significance of hierarchical indexing in Pandas?"
      ],
      "metadata": {
        "id": "Nf_BwWQicKCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Hierarchical indexing in Pandas, also known as MultiIndex, allows for the organization of data in a more flexible and multi-dimensional way by allowing multiple levels of indexing in rows and columns. This feature enables complex data structures to be represented efficiently, which is particularly useful when working with multi-dimensional or grouped data, such as time series data with multiple categories or hierarchical levels (e.g., sales data broken down by both region and product type). Hierarchical indexing makes it easier to slice, aggregate, and manipulate such datasets, as it allows for grouping and querying based on multiple levels of indexes. For instance, it’s possible to select data from a specific group or perform operations on specific subsets without reshaping or reorganizing the entire dataset. This capability significantly enhances the power and flexibility of data manipulation in Pandas, allowing for more sophisticated data analysis."
      ],
      "metadata": {
        "id": "ogQ79WzRcOJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques11) What is the role of Seaborn’s pairplot() function?"
      ],
      "metadata": {
        "id": "WPbi6VdocTsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Seaborn’s pairplot() function is a powerful tool for visualizing the relationships between multiple variables in a dataset. It creates a matrix of scatter plots for each pair of variables, making it easy to observe correlations, distributions, and patterns in the data. Along the diagonal of the matrix, pairplot() typically shows univariate distributions of each variable (such as histograms or kernel density estimates), while the off-diagonal elements display pairwise scatter plots. This function is particularly useful in exploratory data analysis (EDA) because it helps identify trends, clusters, and potential outliers across several features simultaneously. pairplot() also allows for additional customization, such as grouping data by categorical variables using different colors or adding regression lines, making it an essential tool for quickly understanding the relationships in a dataset with multiple numerical features."
      ],
      "metadata": {
        "id": "ct6ubuylcYOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques12) What is the purpose of the describe() function in Pandas?"
      ],
      "metadata": {
        "id": "Qu0rORHNcdOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The describe() function in Pandas is used to generate summary statistics of a DataFrame or Series, providing a quick overview of the key numerical properties of the data. It computes and returns various descriptive statistics, including the count, mean, standard deviation, minimum, 25th percentile (Q1), 50th percentile (median), 75th percentile (Q3), and maximum values for each numerical column. This function is extremely useful in the early stages of data analysis because it allows you to quickly assess the distribution, central tendency, and spread of your data, as well as identify potential outliers or issues like missing values. For categorical data, describe() can also return counts and unique values, providing a helpful summary of the data’s structure and variability. It is an essential tool for understanding and summarizing datasets in a concise and efficient manner.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yTl4QVznchN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques13) A Why is handling missing data important in Pandas?"
      ],
      "metadata": {
        "id": "r76ps439cmZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Handling missing data in Pandas is crucial because missing or NaN (Not a Number) values can distort the analysis and lead to inaccurate results. In real-world datasets, it’s common to encounter missing values due to incomplete data collection or errors during data entry. If not handled properly, these missing values can affect statistical calculations, such as mean, median, or regression analysis, and can introduce bias or lead to incorrect conclusions. Pandas provides several methods to handle missing data, such as filling missing values with specific values (e.g., mean or median), forward or backward filling, or dropping rows or columns with missing data. By addressing missing data appropriately, you ensure that the analysis is based on accurate and reliable information, helping to maintain the integrity of your data analysis process and results.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NVuT7nTNctXj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques14) What are the benefits of using Plotly for data visualization?"
      ],
      "metadata": {
        "id": "v6LkrcFycyGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Plotly offers several significant benefits for data visualization, making it a popular choice for interactive and web-based plotting. One of its key advantages is the ability to create interactive plots, allowing users to zoom, pan, hover over data points, and click on elements to explore the data in greater detail. This interactivity enhances user engagement and provides a deeper understanding of the underlying patterns and relationships in the data. Plotly also supports a wide range of chart types, from basic line and bar charts to complex visualizations like 3D scatter plots, heatmaps, and geographical maps. It integrates seamlessly with web applications, making it ideal for building interactive dashboards and data-driven websites. Furthermore, Plotly’s plots are aesthetically appealing with polished, modern designs out-of-the-box, requiring minimal customization. It also supports integration with other tools and frameworks like Dash for building full-fledged interactive applications. Overall, Plotly is highly favored for creating visually appealing, interactive, and shareable data visualizations, especially in business and data analysis contexts.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "90mc3HARc1yZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques15) How does NumPy handle multidimensional arrays?"
      ],
      "metadata": {
        "id": "xk4s8NtCc64g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NumPy handles multidimensional arrays through its ndarray object, which is designed to represent n-dimensional arrays. A multidimensional array in NumPy can have any number of dimensions (1D, 2D, 3D, and beyond), and NumPy provides powerful tools to create, manipulate, and perform operations on these arrays. For example, a 2D array (matrix) can be thought of as an array of arrays, where each element can be accessed using two indices (rows and columns). NumPy allows you to easily access and modify elements, slices, or entire subarrays using indexing and slicing techniques. It also supports broadcasting, which makes it possible to perform arithmetic operations between arrays of different shapes in a way that aligns dimensions automatically. Operations on multidimensional arrays are vectorized, meaning that they are performed efficiently at the low level without the need for explicit loops, making NumPy particularly well-suited for working with large, multidimensional datasets. This ability to efficiently handle and manipulate arrays with multiple dimensions is one of the reasons NumPy is widely used in scientific computing, machine learning, and data analysis.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bKAvz5lWdAdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques16) What is the role of Bokeh in data visualization?"
      ],
      "metadata": {
        "id": "7f10yd8ZdGpT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bokeh is a powerful Python library for creating interactive, web-based data visualizations. It is particularly well-suited for creating dashboards, reports, and visualizations that can be embedded in web applications or shared online. Unlike static libraries like Matplotlib, Bokeh is designed to produce interactive plots, enabling users to zoom, pan, hover, and click on data points to gain deeper insights. It supports a wide range of visualizations, including basic charts, bar plots, scatter plots, heatmaps, and more complex visualizations like geographical maps and network diagrams. One of Bokeh's main strengths is its ability to seamlessly integrate with web technologies, such as HTML, JavaScript, and CSS, allowing for the creation of highly customizable visualizations that can be easily embedded in web pages or used in interactive applications. Bokeh also provides tools for linking multiple plots together, enabling dynamic and responsive data exploration. This makes it a popular choice for building data-driven web applications, interactive dashboards, and engaging visualizations that enhance user experience and analysis.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_2EP19_ydKgB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques17)  Explain the difference between apply() and map() in Pandas?"
      ],
      "metadata": {
        "id": "yZL_OBLRdSay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In Pandas, both apply() and map() are used to apply functions to data, but they differ in scope, flexibility, and how they handle different types of data.\n",
        "\n",
        "  - apply() is a more general and versatile method that can be used on both Series and DataFrames. When used on a Series, it applies a function to each element of the Series. When used on a DataFrame, it applies a function either along rows or columns (using the axis parameter). This flexibility makes apply() suitable for a wide range of operations, from element-wise transformations to more complex functions that involve entire rows or columns.\n",
        "\n",
        " - map(), on the other hand, is a more specialized method that is specifically used with Series. It is typically used to map or transform each element in a Series based on a dictionary, a function, or a Series of values. It's often simpler and faster than apply() for element-wise transformations, especially when you need to replace or transform values in a column based on a predefined mapping or function.\n",
        "\n",
        " - In summary, apply() is more flexible and can handle both Series and DataFrames, allowing more complex operations, while map() is more efficient and straightforward for element-wise transformations on a single Series."
      ],
      "metadata": {
        "id": "Ekd6n36IdWH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques18) What are some advanced features of NumPy?"
      ],
      "metadata": {
        "id": "QhONmhHgdk4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NumPy offers several advanced features that enhance its functionality and make it an essential tool for scientific and numerical computing. One of these features is broadcasting, which allows NumPy to perform arithmetic operations on arrays of different shapes without the need for explicit looping or reshaping. This makes it easier and more efficient to work with arrays that do not have the same dimensions. Another advanced feature is linear algebra functions, which include operations like matrix multiplication, eigenvalue computation, and solving systems of linear equations, all optimized for performance. NumPy also supports random number generation, providing a suite of functions for generating random data with different distributions, which is useful in simulations and statistical modeling. For users working with large datasets, NumPy includes advanced memory management capabilities, such as views and shallow copies, which allow more efficient data handling. Additionally, NumPy supports strided arrays, which enable memory-efficient slicing of large arrays without copying data, and offers low-level C-API integration, allowing seamless interaction with external C, C++, or Fortran code. These advanced features make NumPy a powerful tool for anyone working with large-scale, high-performance numerical computing tasks.\n"
      ],
      "metadata": {
        "id": "UgeJCLWFdopM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques19) How does Pandas simplify time series analysis?"
      ],
      "metadata": {
        "id": "3gffbS-adv5P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Pandas simplifies time series analysis by providing robust tools specifically designed for working with temporal data. It allows you to easily convert data into Datetime objects, which enables seamless manipulation, filtering, and aggregation of time-based data. With Pandas, you can easily resample time series data (e.g., downsampling from daily to monthly data or upsampling from hourly to minute-level data), perform date shifting, and handle missing values efficiently. It also supports time-based indexing, allowing for quick access to data based on time intervals, such as selecting data from a specific date range or calculating rolling statistics (like moving averages). Additionally, Pandas offers built-in support for time zone handling, which is essential when working with global datasets across different time zones. With its rich set of features and intuitive syntax, Pandas significantly reduces the complexity of time series analysis, making it easier to preprocess, analyze, and visualize time-related data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IFC9DaXVdzpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques20) What is the role of a pivot table in Pandas?"
      ],
      "metadata": {
        "id": "5lfKFp3gd5xx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A pivot table in Pandas is a powerful tool used for summarizing and aggregating data, especially when working with large datasets. It allows you to reshape data by organizing it into a new table, where rows and columns are grouped by specific variables, and summary statistics (such as sum, mean, or count) are calculated for each combination of row and column. This enables you to perform multi-dimensional analysis with ease. For example, a pivot table can help you calculate the total sales per product category across different regions, or find the average temperature for each city over different months. Pivot tables in Pandas are created using the pivot_table() function, which supports various aggregation functions, such as sum(), mean(), or custom functions, making it a versatile tool for data analysis. By simplifying the process of grouping and aggregating data, pivot tables make it easier to extract meaningful insights from complex datasets, often providing a clear overview of trends and relationships within the data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SDgl23Vmd_gQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques21) Why is NumPy’s array slicing faster than Python’s list slicing?"
      ],
      "metadata": {
        "id": "g37LZu7ieLIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NumPy’s array slicing is faster than Python’s list slicing primarily because of the way NumPy arrays are implemented in memory. NumPy arrays are stored in contiguous blocks of memory, meaning that all elements are stored in a single, continuous segment, which allows for efficient access and manipulation. When slicing a NumPy array, it creates a view of the original data, rather than copying the data. This results in faster slicing operations, as it doesn't require creating a new array or copying data, but rather provides a reference to the original array. In contrast, Python lists are more flexible but less memory-efficient, and list slicing involves creating a new copy of the sliced portion of the list, which adds overhead. Additionally, NumPy is implemented in C, allowing for low-level optimizations that further speed up array operations. This combination of contiguous memory storage, efficient slicing via views, and optimized C code makes NumPy slicing much faster than Python list slicing, especially when working with large datasets.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SF0fBk8zeP4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques22) What are some common use cases for Seaborn?"
      ],
      "metadata": {
        "id": "T_ZKitWMeVT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Seaborn is widely used for statistical data visualization in Python, particularly for tasks that involve exploring relationships between variables, understanding data distributions, and identifying patterns or trends. Common use cases for Seaborn include creating distribution plots, such as histograms, kernel density estimates (KDE), and box plots, to visualize the spread and distribution of data. It's also frequently used for relationship plots, such as scatter plots and pair plots, to investigate correlations or patterns between numerical variables. Seaborn is excellent for categorical plots, like bar plots, count plots, and violin plots, which are useful for comparing values across different categories. Furthermore, Seaborn’s built-in support for heatmaps makes it an ideal tool for visualizing correlation matrices, showing how different features in a dataset relate to one another. Another key feature is its ability to create regression plots, which helps in understanding the relationship between two variables, along with adding trend lines to illustrate linear relationships. In general, Seaborn simplifies the process of generating aesthetically pleasing, informative, and publication-quality visualizations, making it ideal for exploratory data analysis and presenting findings in a clear and visually compelling way.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2uCN9d75eZoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practical Question"
      ],
      "metadata": {
        "id": "2MbeCsdieh5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques1) How do you create a 2D NumPy array and calculate the sum of each row?"
      ],
      "metadata": {
        "id": "GGevQSBbemaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "array_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "\n",
        "row_sums = np.sum(array_2d, axis=1)\n",
        "\n",
        "print(\"2D Array:\")\n",
        "print(array_2d)\n",
        "print(\"\\nSum of each row:\")\n",
        "print(row_sums)\n"
      ],
      "metadata": {
        "id": "PKqeCWXwev54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques2) A Write a Pandas script to find the mean of a specific column in a DataFrame?"
      ],
      "metadata": {
        "id": "UwyIY-UbeyU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "data = {'Column1': [10, 20, 30, 40, 50],\n",
        "        'Column2': [5, 15, 25, 35, 45],\n",
        "        'Column3': [2, 4, 6, 8, 10]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "mean_column1 = df['Column1'].mean()\n",
        "\n",
        "print(\"Mean of 'Column1':\", mean_column1)\n"
      ],
      "metadata": {
        "id": "2kBF3zQje33h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques3) Create a scatter plot using Matplotlib?"
      ],
      "metadata": {
        "id": "nzAgs2XXfAZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y = [2, 4, 6, 8, 10]\n",
        "\n",
        "\n",
        "plt.scatter(x, y)\n",
        "\n",
        "plt.title('Basic Scatter Plot')\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oMNSqgXNfDsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques4) How do you calculate the correlation matrix using Seaborn and visualize it with a heatmap?"
      ],
      "metadata": {
        "id": "gDbwQ6h9fK1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'A': [1, 2, 3, 4, 5],\n",
        "        'B': [5, 4, 3, 2, 1],\n",
        "        'C': [2, 3, 4, 5, 6],\n",
        "        'D': [7, 8, 9, 10, 11]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Create a heatmap to visualize the correlation matrix\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "\n",
        "# Adding a title\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2F5z6W2dfOpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques5) Generate a bar plot using Plotly?"
      ],
      "metadata": {
        "id": "t7d6GIQQfTYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Sample data\n",
        "categories = ['Category A', 'Category B', 'Category C', 'Category D']\n",
        "values = [10, 15, 7, 20]\n",
        "\n",
        "# Create the bar plot\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Bar(\n",
        "            x=categories,\n",
        "            y=values,\n",
        "            text=values,\n",
        "            textposition='auto',\n",
        "            marker_color='blue',  # Change the bar color\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Add title and labels\n",
        "fig.update_layout(\n",
        "    title='Bar Plot Example',\n",
        "    xaxis_title='Categories',\n",
        "    yaxis_title='Values',\n",
        "    template='plotly_white',  # Optional: Change the theme\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "mecHpRGdfXnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques6) Create a DataFrame and add a new column based on an existing column?"
      ],
      "metadata": {
        "id": "YXLHX04agHdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Score': [85, 90, 78, 92]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Add a new column based on an existing column\n",
        "# For example, categorizing scores\n",
        "df['Category'] = df['Score'].apply(lambda x: 'High' if x >= 90 else 'Low')\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "5wfBxzdagNL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques7)  Write a program to perform element-wise multiplication of two NumPy arrays?"
      ],
      "metadata": {
        "id": "IBLcuq5KgVQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create two NumPy arrays\n",
        "array1 = np.array([1, 2, 3, 4, 5])\n",
        "array2 = np.array([10, 20, 30, 40, 50])\n",
        "\n",
        "# Perform element-wise multiplication\n",
        "result = array1 * array2\n",
        "\n",
        "# Display the result\n",
        "print(\"Array 1:\", array1)\n",
        "print(\"Array 2:\", array2)\n",
        "print(\"Element-wise Multiplication:\", result)\n"
      ],
      "metadata": {
        "id": "75elpxgCgYvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques8)  Create a line plot with multiple lines using Matplotlib?"
      ],
      "metadata": {
        "id": "oAZT6RAQgdBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y1 = [2, 4, 6, 8, 10]  # Line 1\n",
        "y2 = [1, 3, 5, 7, 9]   # Line 2\n",
        "y3 = [3, 6, 9, 12, 15] # Line 3\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "plt.plot(x, y1, label='Line 1', marker='o', color='blue')  # Plot Line 1\n",
        "plt.plot(x, y2, label='Line 2', marker='s', color='green') # Plot Line 2\n",
        "plt.plot(x, y3, label='Line 3', marker='^', color='red')   # Plot Line 3\n",
        "\n",
        "# Add labels, title, and legend\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n",
        "plt.title('Multiple Line Plot Example')\n",
        "plt.legend(loc='upper left')  # Display the legend in the upper-left corner\n",
        "\n",
        "# Display the grid\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mGjj4RY0gg0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques9)  Generate a Pandas DataFrame and filter rows where a column value is greater than a threshold?"
      ],
      "metadata": {
        "id": "_0GmSpNFgm8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [25, 32, 18, 45],\n",
        "    'Score': [85, 90, 78, 92]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the threshold\n",
        "threshold = 80\n",
        "\n",
        "# Filter rows where the 'Score' column is greater than the threshold\n",
        "filtered_df = df[df['Score'] > threshold]\n",
        "\n",
        "# Display the filtered DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nFiltered DataFrame (Score > {}):\".format(threshold))\n",
        "print(filtered_df)\n"
      ],
      "metadata": {
        "id": "FH9nSC1mgqJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques10)  Create a histogram using Seaborn to visualize a distribution?"
      ],
      "metadata": {
        "id": "riFVfiMFgt07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate sample data\n",
        "data = np.random.normal(loc=50, scale=10, size=500)  # Normal distribution, mean=50, std=10\n",
        "\n",
        "# Create the histogram\n",
        "sns.set(style=\"whitegrid\")  # Set a nice grid style\n",
        "plt.figure(figsize=(8, 5))  # Set figure size\n",
        "\n",
        "sns.histplot(data, bins=30, kde=True, color=\"blue\", alpha=0.6)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram with Seaborn')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Jlw7RWxTgxVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques11) Perform matrix multiplication using NumPy?"
      ],
      "metadata": {
        "id": "JudGvmzJg1V7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define two matrices\n",
        "matrix_a = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "matrix_b = np.array([[7, 8], [9, 10], [11, 12]])\n",
        "\n",
        "# Perform matrix multiplication\n",
        "result = np.dot(matrix_a, matrix_b)\n",
        "\n",
        "# Display the matrices and result\n",
        "print(\"Matrix A:\")\n",
        "print(matrix_a)\n",
        "print(\"\\nMatrix B:\")\n",
        "print(matrix_b)\n",
        "print(\"\\nResult of Matrix Multiplication:\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "DhcTHbbXg4Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques12)  Use Pandas to load a CSV file and display its first 5 rows?"
      ],
      "metadata": {
        "id": "kdSteOwhg8kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "# Replace 'your_file.csv' with the actual path to your CSV file\n",
        "file_path = 'your_file.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(\"First 5 rows of the DataFrame:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "i82LB4EBhAGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques13)  Create a 3D scatter plot using Plotly?"
      ],
      "metadata": {
        "id": "94ljLh2AhEPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Sample data\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y = [10, 15, 20, 25, 30]\n",
        "z = [5, 10, 15, 20, 25]\n",
        "\n",
        "# Create the 3D scatter plot\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Scatter3d(\n",
        "            x=x,\n",
        "            y=y,\n",
        "            z=z,\n",
        "            mode='markers',\n",
        "            marker=dict(\n",
        "                size=8,\n",
        "                color=z,  # Use z values for color\n",
        "                colorscale='Viridis',  # Color scale\n",
        "                opacity=0.8\n",
        "            )\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Add layout details\n",
        "fig.update_layout(\n",
        "    title='3D Scatter Plot',\n",
        "    scene=dict(\n",
        "        xaxis_title='X-axis',\n",
        "        yaxis_title='Y-axis',\n",
        "        zaxis_title='Z-axis'\n",
        "    ),\n",
        "    template='plotly_white'\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "qMFv9MYxhIan"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}